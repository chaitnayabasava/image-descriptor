# Image Descriptor

### The goal of the project is to generate dense captions for images by learning visual representations from the rich text descriptions.

## Hypothesis: 
> MS COCO dataset has 5 captions for each image in the dataset. These are rich dense captions which contains information about the image (descriptive and positional). If we can use this information to learn the visual representations we belive this could perform much better on the downstream tasks

## Dataset
> MS COCO - Image Captioning Dataset

## Task List
 - [ ] Reproduce the results of [VirTex: Learning Visual Representations from Textual Annotations](https://arxiv.org/abs/2006.06666)
 - [ ] Create Web App for Inference
 - [ ] Improve Textual Head

## Technology Stack:
> PyTorch

## Install dependencies
``` pip install -r requirements.txt ```

## Team:
- [Sumanth Doddapaneni](https://www.linkedin.com/in/sumanth-doddapaneni-25494b130/)
- [BSNV Chaitanya](https://www.linkedin.com/in/basava-sai-naga-viswa-chaitanya-665083172/)
- [Rusheel Gollakota](https://www.linkedin.com/in/rusheel-gollakota-028612145/) 